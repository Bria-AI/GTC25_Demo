{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** This code requires a Bria API token: https://platform.bria.ai/register "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"api_token\": os.getenv(\"BRIA_API_TOKEN\")  # Ensure BRIA_API_TOKEN is set in your environment variables\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Bria: AI-Powered Visual Content Generation\n",
    "\n",
    "Bria is a visul-Gen-AI platform for builders, designed for commercial use and powered exclusively by licensed data.\n",
    "\n",
    "This demo will showcase how developers can leverage Bria's APIs to build tools that enable their users to generate and modify brand-consistent visuals at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images([Image.open(\"./visuals/bria_intro1.jpg\"), Image.open(\"./visuals/bria_intro2.jpg\")], resize=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leveraging Gen-AI for Brand Content Creation\n",
    "\n",
    "We'll use **Bria's API** to show how a developer can easily **build** tools for creating and editing **controlled**, **on-brand** visuals **at scale**.\n",
    "\n",
    "A strong brand identity includes visual features such as:\n",
    "\n",
    "- **Color Palette**\n",
    "- **Style & Mood**\n",
    "- **Recurring Characters (\"mascot\") & Themes** \n",
    "- **Fonts** \n",
    "- **Logo**\n",
    "\n",
    "The example below showcases how such features are present in the Bria brand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images([Image.open(\"./visuals/bria_brand_example.png\")], resize=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text-to-Image**: AI-Generated Visuals\n",
    "\n",
    "Visual GenAI starts with text-to-image generation. \n",
    "\n",
    "Below, we define a function to generate images from a prompt using Bria's **text-to-image API**:\n",
    "\n",
    "https://docs.bria.ai/image-generation/endpoints/text-to-image-fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_image(prompt, num_results=3, model_version=\"2.3\", fast=False, seed=42):\n",
    "    \"\"\"\n",
    "    Generate AI-powered images from text prompts using Bria's API.\n",
    "    \n",
    "    Parameters:\n",
    "    - prompt (str): The text description of the desired image.\n",
    "    - model_version (str): foundation model version to use.\n",
    "    - num_results (int): Number of images to generate.\n",
    "    - fast (bool): Whether to use the fast generation endpoint.\n",
    "    - seed (int): Seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    - List of generated image objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = f\"https://engine.prod.bria-api.com/v1/text-to-image/base/{model_version}\"\n",
    "    if fast:\n",
    "        base_url = f\"https://engine.prod.bria-api.com/v1/text-to-image/fast/{model_version}\"\n",
    "\n",
    "    payload = {\n",
    "        \"prompt\": prompt, \n",
    "        \"seed\": seed, \n",
    "        \"num_results\": num_results,\n",
    "        \"sync\": True, \n",
    "    }\n",
    "\n",
    "    response = requests.post(base_url, json=payload, headers=headers)\n",
    "    responses = response.json().get(\"result\", [{}])\n",
    "    print(responses[0].get(\"warning\",\"\"))\n",
    "    image_urls = [x.get(\"urls\", [None])[0] for x in responses]\n",
    "\n",
    "    return return_images_from_urls(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: Generating an Image with Bria\n",
    "# The following example demonstrates how Bria's API generates AI-driven visuals from text descriptions.\n",
    "\n",
    "prompt = 'A 3D render of a purple skinned elephant, over white background'\n",
    "\n",
    "images = text_to_image(prompt, num_results=3)\n",
    "display_images(images, f\"prompt: {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Briaâ€™s Responsible AI**\n",
    "\n",
    "Bria ensures content safety by preventing the generation of copyrighted material. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A 3D render of a purple skinned elephant, that resembels Disney's Dumbo\"\n",
    "images = text_to_image(prompt)\n",
    "display_images(images, f\"prompt: {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generating the same prompt with Flux we get the following result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images([Image.open(\"./visuals//flux_dumbo.png\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducing The Brand Mascot\n",
    "\n",
    "We want to enable users to accurately create visuals using their brand assets, such as the following examples of the **Bria Elephant**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample of bria elephant oiriginal images\n",
    "\n",
    "bria_bear_dir = \"briaphant\"\n",
    "images = [Image.open(f\"{bria_bear_dir}/{f}\") for f in os.listdir(bria_bear_dir) if \"png\" in f][:4]\n",
    "display_images(images, \"Bria Elephant - Originals\", resize = 1000, font_size=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add more components to the text-to-image generation to increase the controlability. We'll start by introducing **Control-Nets**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Guidance for Controlled Generation\n",
    "We can add **structural control** using an input image to generate variations of that image, using the following Control Nets which were trained on-top of Bria's foundation text-to-image model:\n",
    "- Canny\n",
    "- Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images([Image.open(\"./visuals/control_nets.png\")], resize=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll choose one of the Bria Elephant original images and add structural image guidance to the generation using our trained ControlNets.\n",
    "\n",
    "We can use Bria's **Reimagine API** which combines both ControlNets to reproduce the structure of the input image, while allowing changes through the textual prompt:\n",
    "\n",
    "https://docs.bria.ai/image-generation/endpoints/reimagine-structure-reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_image_with_guidance(prompt, guidance_image, num_results=3, fast=False, seed=42):\n",
    "    \n",
    "    base_url = \"https://engine.prod.bria-api.com/v1/reimagine\"\n",
    "\n",
    "    payload = {\n",
    "        \"prompt\": prompt, \n",
    "        \"seed\": seed, \n",
    "        \"num_results\": num_results,\n",
    "        \"sync\": True, \n",
    "        \"structure_image_file\": pil_image_to_base64(guidance_image),\n",
    "        \"fast\": fast\n",
    "    }\n",
    "    \n",
    "    response = requests.post(base_url, json=payload, headers=headers)\n",
    "    responses = response.json().get(\"result\", [{}])\n",
    "    image_urls = [x.get(\"urls\", [None])[0] for x in responses]\n",
    "\n",
    "    return return_images_from_urls(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input:\n",
    "prompt = 'A 3D render of a purple skinned elephant, over white background'\n",
    "guidance_image = Image.open(\"./briaphant/bria_1afcb261_2000_49eb_a908_3656fd9a67fd_4.png\")\n",
    "\n",
    "images = text_to_image_with_guidance(prompt, guidance_image, num_results=2)\n",
    "display_images([guidance_image], 'Input Image')\n",
    "display_images(images, f\"prompt: {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Reimagine to change the color of the Bria Elephant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for color in ['blue', 'green', 'brown', 'rainbow colored']:\n",
    "    prompt = f'A 3D render of a {color} skinned elephant, over white background'\n",
    "    \n",
    "    guidance_image = Image.open(\"./briaphant/bria_1afcb261_2000_49eb_a908_3656fd9a67fd_4.png\")\n",
    "\n",
    "    image = text_to_image_with_guidance(prompt, guidance_image, num_results=1)\n",
    "    images.append(image[0])\n",
    "display_images(images, 'prompt: A 3D render of a {color} skinned elephant, over white background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases this structural control is not enough. We want to enable our users to teach the model to generate a more accurate and varied represenation of this character.\n",
    "\n",
    "We will allow this by enabling our users to **fine-tune** our foundation model using the original brand images they own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tailored-Generation - Fine-Tuning with LoRA\n",
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fine-tune Bria's foundation model using the existing images of the Bria Elephant. For fine-tuning we would use Bria's **4B-Adapt** model, which is designed to provide exceptional fine-tuning capabilities for commercial use: https://huggingface.co/briaai/BRIA-4B-Adapt\n",
    "\n",
    "\n",
    "We fine-tune using LoRA for easier deployment of each such fine-tuned model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Please refer to the following examples:\n",
    "\n",
    "- Training using Bria's automatic Tailored-Gen API: gtc_demo_fine_tune_api.ipynb\n",
    "\n",
    "- Training on-prem using Bria's foundation model weights on HF: gtc_demo_fine_tune_on_prem.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We'll use Bria's Generate Image - Tailored Model API:\n",
    "\n",
    "https://docs.bria.ai/tailored-generation/endpoints/text-to-image-tailored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tailored_gen(prompt, tailored_model, num_results=3, seed=42):\n",
    "    \n",
    "    base_url = f\"https://engine.prod.bria-api.com/v1/text-to-image/tailored/{tailored_model}\"\n",
    "\n",
    "    payload = {\n",
    "        \"prompt\": prompt, \n",
    "        \"seed\": seed, \n",
    "        \"num_results\": num_results,\n",
    "        \"sync\": True, \n",
    "    }\n",
    "\n",
    "    response = requests.post(base_url, json=payload, headers=headers)\n",
    "    responses = response.json().get(\"result\", [{}])\n",
    "    image_urls = [x.get(\"urls\", [None])[0] for x in responses]\n",
    "\n",
    "    return return_images_from_urls(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"holding a pink cocktail in its trunk and wearing a small pink party hat\"\n",
    "tailored_model = 10920\n",
    "elephant_image = tailored_gen(prompt, tailored_model, num_results=1)[0]\n",
    "elephant_image.save('./api_results/elephant_image.jpg')\n",
    "display_images([elephant_image], f\"prompt: \\n{prompt}\", font_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now let's place this festive character in a proper location by generating on-brand backgrounds.\n",
    "\n",
    "We want the background to adhere to the brand style as well, so we'll use a tailored model trained on the following brand style images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample of bria style oiriginal images\n",
    "bria_style_dir = \"bria_style\"\n",
    "\n",
    "images = [Image.open(f\"{bria_style_dir}/{f}\") for f in os.listdir(bria_style_dir)][:4]\n",
    "display_images(images, \"Bria Style - Originals\", resize = 1000, font_size=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used an LLM to write a few prompts for background images that could be relevant for this character in a festive event. \n",
    "\n",
    "Let's generate 1 example from each, using the brand style tailored model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_prompts = [\n",
    " 'A tropical beach at sunset with palm trees, soft waves, and string lights, perfect for a relaxing party vibe',\n",
    " 'A winter wonderland party with twinkling snowflakes, icy-blue lighting, and festive holiday purple decorations creating a cozy atmosphere',\n",
    " 'A cosmic galaxy party with glowing planets, swirling nebulas, and a dance floor that looks like the surface of the moon.',\n",
    " 'A lively party venue with colorful decorations, balloons, streamers, and warm lighting, creating a fun and festive atmosphere',\n",
    " 'A carnival-themed party with bright lights, a Ferris wheel in the background, colorful booths, and festive decorations',\n",
    " 'A futuristic space party with floating balloons, glowing neon decorations, and a starry galaxy sky in the background',\n",
    " \"A retro '80s party with neon colors, arcade machines, a checkered dance floor, and a boombox playing classic hits.\",\n",
    " 'A jungle adventure party with tropical foliage, tiki torches, tribal drums, and exotic animals hidden in the background.',\n",
    " 'A rooftop sunset cocktail party with stylish lounge seating, golden hour lighting, and a panoramic city skyline view.'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_originals_dir = \"./api_results/bg_gen/bg_originals\"\n",
    "os.makedirs(bg_originals_dir, exist_ok=True)\n",
    "\n",
    "all_bg_images = []\n",
    "for i, prompt in enumerate(background_prompts):\n",
    "    tailored_model = 10900\n",
    "    bg_image = tailored_gen(prompt, tailored_model, num_results=1)[0]\n",
    "    bg_image.save(f'{bg_originals_dir}/{i}.png')\n",
    "    all_bg_images.append(bg_image)\n",
    "\n",
    "all_bg_images = [Image.open(f'{bg_originals_dir}/{i}.png') for i in range(len(background_prompts))]\n",
    "display_images(all_bg_images[:3], f\"Generated Backgrounds from Bria Style Tailored Model\", resize = 256)\n",
    "display_images(all_bg_images[3:6], resize = 256)\n",
    "display_images(all_bg_images[6:9], resize = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Genreation (by Reference Image)\n",
    "Next, we want to use those brand style backgrounds as inspiration for new background for our festive Bria Elephant. \n",
    "\n",
    "We'll use Bria's Generate Background API:\n",
    "\n",
    "\n",
    "https://docs.bria.ai/image-editing/endpoints/background-replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bg_by_image(foreground_image, bg_image, num_results=1, seed=42, padding=[0, 0, 0, 0]):\n",
    "    \n",
    "    base_url = \"https://engine.prod.bria-api.com/v1/background/replace\"\n",
    "\n",
    "    payload = {\n",
    "        \"file\": pil_image_to_base64(foreground_image),\n",
    "        \"ref_image_file\": pil_image_to_base64(bg_image),\n",
    "        \"sync\": True,\n",
    "        \"placement_type\": \"manual_padding\",\n",
    "        \"num_results\": num_results,\n",
    "        \"seed\": seed,         \n",
    "        \"padding_values\": padding\n",
    "    }\n",
    "\n",
    "    response = requests.post(base_url, json=payload, headers=headers)\n",
    "    responses = response.json().get(\"result\", [{}])\n",
    "    image_urls = [x[0] for x in responses]\n",
    "\n",
    "    return return_images_from_urls(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_generations_dir = \"./api_results/bg_gen/bg_generations\"\n",
    "os.makedirs(bg_generations_dir, exist_ok=True)\n",
    "\n",
    "all_bg_images = [Image.open(f'{bg_originals_dir}/{i}.png') for i in range(len(background_prompts))]\n",
    "\n",
    "foreground_image = Image.open('elephant_image.jpg')\n",
    "resize_scale = 0.25 # we'll make the elephant 25% smaller to fit into the background images\n",
    "\n",
    "# we want the elephant to be positioned in the bottom right corner of the background image, so we'll add padding accordingly\n",
    "width_padding = int(foreground_image.size[0]*resize_scale)\n",
    "height_padding = int(foreground_image.size[1]*resize_scale)\n",
    "bottom_right_location = [width_padding, 0, height_padding, 0]\n",
    "\n",
    "all_images = []\n",
    "for i, bg_img in enumerate(all_bg_images):\n",
    "\n",
    "    new_bg_img = generate_bg_by_image(foreground_image, bg_img, num_results=1, padding=bottom_right_location)\n",
    "    new_bg_img[0].save(f'{bg_generations_dir}/{i}.png')\n",
    "    all_images.append(new_bg_img[0])\n",
    "\n",
    "# all_images = [Image.open(f'/home/ubuntu/spring/demo_gtc/bg_gen/bg_generations/{i}.png') for i in range(len(background_prompts))]\n",
    "\n",
    "display_images(all_images[:3], f\"Replaced Backgrounds with Reference Images\", resize = 256)\n",
    "display_images(all_images[3:6], resize = 256)\n",
    "display_images(all_images[6:9], resize = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Editing: Generative Fill\n",
    "\n",
    "Focusing on the first 3 outputs, let's fix some content issues by replacing or adding content using Bria's Generative-Fill API:\n",
    "\n",
    "https://docs.bria.ai/image-editing/endpoints/gen-fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fill(original_image, mask, prompt, num_results=1, seed=42):\n",
    "    \n",
    "    base_url = \"https://engine.prod.bria-api.com/v1/gen_fill\"\n",
    "\n",
    "    payload = {\n",
    "        \"file\": pil_image_to_base64(original_image),\n",
    "        \"mask_file\": pil_image_to_base64(mask.convert('RGB')),\n",
    "        \"mask_type\": \"manual\",\n",
    "        \"prompt\": prompt,\n",
    "        \"num_results\": num_results,\n",
    "        \"sync\": True,\n",
    "        \"seed\": seed,\n",
    "    }\n",
    "\n",
    "    response = requests.post(base_url, json=payload, headers=headers)\n",
    "    responses = response.json().get(\"urls\", [])\n",
    "    image_urls = [x for x in responses]\n",
    "\n",
    "    return return_images_from_urls(image_urls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first image is a beach scene, let's replace the party hat with some beachwear. We'll use a mask around the hat we want to replace, and specifiy the new content in \"prompt\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open('./api_results/bg_gen/bg_generations/0.png')\n",
    "mask = Image.open('./api_results/masks/hat_mask.png')\n",
    "prompt = \"a straw hat\"\n",
    "\n",
    "display_mask(mask, input_image)\n",
    "\n",
    "output_var1 = gen_fill(input_image, mask, prompt)[0]\n",
    "output_var1.save(f'./api_results/bg_gen/bg_generations/0_fixed.png')\n",
    "display_images([output_var1], f\"prompt: {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's replace the hat in the second image to something more suitable for winter festivities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open(f'./api_results/bg_gen/bg_generations/1.png')\n",
    "mask = Image.open('./api_results/masks/hat_mask.png')\n",
    "prompt = \"a santa hat\"\n",
    "\n",
    "output_var2 = gen_fill(input_image, mask, prompt)[0]\n",
    "output_var2.save(f'./api_results/bg_gen/bg_generations/1_fixed.png')\n",
    "display_images([output_var2], f\"prompt: {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add a christmas tree in the brand colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open(f'./api_results/bg_gen/bg_generations/1_fixed.png')\n",
    "mask = Image.open('./api_results/masks/tree_mask.png')\n",
    "prompt = \"a lush christmas tree with purple and pink ornaments\"\n",
    "\n",
    "display_mask(mask, input_image)\n",
    "\n",
    "output_var2 = gen_fill(input_image, mask, prompt)[0]\n",
    "output_var2.save(f'./api_results/bg_gen/bg_generations/1_fixed.png')\n",
    "display_images([output_var2], f\"prompt: \\n{prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Editing: Eraser\n",
    "And finally, the summer cocktail doesn't align with the winter theme, so let's remove it. \n",
    "\n",
    "We'll use Bria's Eraser API:\n",
    "\n",
    "https://docs.bria.ai/image-editing/endpoints/eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erase(original_image, mask):\n",
    "    \n",
    "    base_url = \"https://engine.prod.bria-api.com/v1/eraser\"\n",
    "\n",
    "    payload = {\n",
    "        \"file\": pil_image_to_base64(original_image),\n",
    "        \"mask_file\": pil_image_to_base64(mask.convert('RGB')),\n",
    "        \"mask_type\": \"manual\",\n",
    "        \"sync\": True,\n",
    "    }\n",
    "\n",
    "    response = requests.post(base_url, json=payload, headers=headers)\n",
    "    responses = response.json().get(\"result_url\", '')\n",
    "    image_urls = [responses]\n",
    "\n",
    "    return return_images_from_urls(image_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open(f'./api_results/bg_gen/bg_generations/1_fixed.png')\n",
    "mask = Image.open('./api_results/masks/cocktail_mask.png')\n",
    "\n",
    "display_mask(mask, input_image)\n",
    "\n",
    "output_var2 = erase(input_image, mask)[0]\n",
    "output_var2.save(f'./api_results/bg_gen/bg_generations/1_fixed.png')\n",
    "display_images([output_var2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Editing: Expand\n",
    "\n",
    "We now have our 3 image varaiations ready. But what if we wanted to use them in adds with different aspect ratios? \n",
    "\n",
    "We'll use Bria's Expand Image API to expand the image to different aspect ratios:\n",
    "\n",
    "https://docs.bria.ai/image-editing/endpoints/image-expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_var3 = Image.open(f'./api_results/bg_gen/bg_generations/2.png').resize((350, 350))\n",
    "image_variations = [output_var1, output_var2, output_var3]\n",
    "display_images(image_variations, resize = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_left(input_image, seed=1000):\n",
    "    org_width, org_height = input_image.size\n",
    "    \n",
    "    base_url = \"https://engine.prod.bria-api.com/v1/image_expansion\"\n",
    "\n",
    "    payload = {\n",
    "        \"file\": pil_image_to_base64(input_image),\n",
    "        \"canvas_size\": [\n",
    "            org_width*2,\n",
    "            org_height\n",
    "        ],\n",
    "        \"original_image_size\": [\n",
    "            org_width,\n",
    "            org_height\n",
    "        ],\n",
    "        \"original_image_location\": [\n",
    "            org_width,\n",
    "            0\n",
    "        ],\n",
    "        \"seed\": seed\n",
    "    }\n",
    "\n",
    "    response = requests.post(base_url, json=payload, headers=headers)\n",
    "    responses = response.json().get(\"result_url\", '')\n",
    "    image_urls = [responses]\n",
    "\n",
    "    return return_images_from_urls(image_urls)\n",
    "\n",
    "def expand_top(input_image, seed=1000):\n",
    "    org_width, org_height = input_image.size\n",
    "    \n",
    "    base_url = \"https://engine.prod.bria-api.com/v1/image_expansion\"\n",
    "\n",
    "    payload = {\n",
    "        \"file\": pil_image_to_base64(input_image),\n",
    "        \"canvas_size\": [\n",
    "            org_width,\n",
    "            org_height*2\n",
    "        ],\n",
    "        \"original_image_size\": [\n",
    "            org_width,\n",
    "            org_height\n",
    "        ],\n",
    "        \"original_image_location\": [\n",
    "            0,\n",
    "            org_height\n",
    "        ],\n",
    "        \"seed\": seed\n",
    "    }\n",
    "\n",
    "    response = requests.post(base_url, json=payload, headers=headers)\n",
    "    responses = response.json().get(\"result_url\", '')\n",
    "    image_urls = [responses]\n",
    "\n",
    "    return return_images_from_urls(image_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_images_left = []\n",
    "for image_var in image_variations:\n",
    "    expanded_images_left.append(expand_left(image_var)[0])\n",
    "\n",
    "display_images(expanded_images_left, resize = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_images_top = []\n",
    "for image_var in image_variations:\n",
    "    expanded_images_top.append(expand_top(image_var)[0])\n",
    "\n",
    "display_images(expanded_images_top, resize = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(image_variations)\n",
    "display_images([pad_image_to_square(x) for x in expanded_images_top])\n",
    "display_images([pad_image_to_square(x) for x in expanded_images_left])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### increase res!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
